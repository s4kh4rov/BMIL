{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/s4kh4rov/BMIL/blob/master/magdiplom.ipynb",
      "authorship_tag": "ABX9TyPIl26hZgJv6O9D4AFtGkBm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s4kh4rov/BMIL/blob/master/magdiplom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3UcFs-beCX39"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import glob\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import imutils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"KlfuZxqMCfq22KG6TKdR\")\n",
        "project = rf.workspace(\"research-xvh79\").project(\"window-detection-vnpow\")\n",
        "dataset = project.version(1).download(\"coco\")\n"
      ],
      "metadata": {
        "id": "lxtkwKMg0-eK",
        "outputId": "2c69105c-5451-438d-e451-e65f60233e72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.19-py3-none-any.whl (70 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.2/70.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2023.7.22 (from roboflow)\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n",
            "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Collecting supervision (from roboflow)\n",
            "  Downloading supervision-0.18.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-magic (from roboflow)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.48.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (0.7.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.4)\n",
            "Installing collected packages: python-magic, python-dotenv, opencv-python-headless, idna, cycler, chardet, certifi, supervision, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.9.0.80\n",
            "    Uninstalling opencv-python-headless-4.9.0.80:\n",
            "      Successfully uninstalled opencv-python-headless-4.9.0.80\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Successfully uninstalled idna-3.6\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.2.2\n",
            "    Uninstalling certifi-2024.2.2:\n",
            "      Successfully uninstalled certifi-2024.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-dotenv-1.0.1 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.19 supervision-0.18.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "chardet",
                  "cv2",
                  "cycler",
                  "idna"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Window-detection-1 to coco:: 100%|██████████| 193551/193551 [00:05<00:00, 37883.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Window-detection-1 in coco:: 100%|██████████| 4848/4848 [00:01<00:00, 3419.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "for file1 in os.listdir('/content/Window-detection-1/train'):\n",
        "  if(file1.endswith('.json')):\n",
        "    save_path = '/content/drive/MyDrive/diplom/'\n",
        "    shutil.move(os.path.join('/content/Window-detection-1/train',file1), save_path)"
      ],
      "metadata": {
        "id": "REZcl4TB7Ytz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getImageNameByImageId (images, id):\n",
        "  for el in images:\n",
        "    if(el['id']==id):\n",
        "      return el['file_name']"
      ],
      "metadata": {
        "id": "HlVRduqOhI89"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resizeImage(width, height, image):\n",
        "  down_points = (width, height)\n",
        "  return cv2.resize(image, down_points, interpolation= cv2.INTER_LINEAR)"
      ],
      "metadata": {
        "id": "PXhLAQD2hgM4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install roboflow\n",
        "\n",
        "# from roboflow import Roboflow\n",
        "# rf = Roboflow(api_key=\"KlfuZxqMCfq22KG6TKdR\")\n",
        "# project = rf.workspace(\"shixi-rqywi\").project(\"stairsdetect-for-blinders\")\n",
        "# dataset = project.version(7).download(\"coco\")\n",
        "\n",
        "all_img_paths = glob.glob(\"/content/STAIRSdetect-FOR-blinders-7/valid/*\")\n",
        "path = '/content/drive/MyDrive/diplom/test/validStairs/'\n",
        "i=0\n",
        "for img_path in all_img_paths:\n",
        "  if(img_path.endswith(\".jpg\")):\n",
        "    img = cv2.imread(img_path)\n",
        "    # img300 = resizeImage(300,300,img)\n",
        "    # imgEdge = cv2.edgePreservingFilter(img300, flags=1, sigma_s=100, sigma_r=0.3)\n",
        "    # imgGray = cv2.cvtColor(imgEdge, cv2.COLOR_BGR2GRAY)\n",
        "    # imgLap = cv2.Laplacian(imgGray, cv2.CV_64F, ksize=5)\n",
        "    cv2.imwrite(os.path.join(path , 'stair'+str(i)+'.jpg'), img)\n",
        "    i+=1\n",
        "print(i)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnRRGu9Ln-Px",
        "outputId": "dbc1801d-cbe7-499d-97fa-0385f71031b5"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# двери\n",
        "# from roboflow import Roboflow\n",
        "# rf = Roboflow(api_key=\"KlfuZxqMCfq22KG6TKdR\")\n",
        "# project = rf.workspace(\"miguel-ortiz\").project(\"door_cls\")\n",
        "# dataset = project.version(3).download(\"folder\")\n",
        "\n",
        "# all_img_paths = glob.glob(\"/content/door_cls-3/test/door_cls/*\")\n",
        "# path = '/content/drive/MyDrive/diplom/colorImages/door/'\n",
        "# i=0\n",
        "# for img_path in all_img_paths:\n",
        "#   img = cv2.imread(img_path)\n",
        "#   img300 = resizeImage(300,300,img)\n",
        "#   imgEdge = cv2.edgePreservingFilter(img300, flags=1, sigma_s=100, sigma_r=0.3)\n",
        "#   imgGray = cv2.cvtColor(imgEdge, cv2.COLOR_BGR2GRAY)\n",
        "#   imgLap = cv2.Laplacian(imgGray, cv2.CV_64F, ksize=5)\n",
        "#   cv2.imwrite(os.path.join(path , 'door'+str(i)+'.jpg'), imgLap)\n",
        "#   i+=1\n",
        "# print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSbw4hgrwHiZ",
        "outputId": "acfe149b-ea97-434f-fe76-f157f0496324"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# окна\n",
        "# import json\n",
        "# f = open('/content/drive/MyDrive/diplom/_annotations.coco.json')\n",
        "# data = json.load(f)\n",
        "# path = '/content/drive/MyDrive/diplom/rfProcessedImages/window/'\n",
        "# img_path = \"/content/Window-detection-1/train/\"\n",
        "# i=0\n",
        "# for annotation in data['annotations']:\n",
        "#   image_id = annotation['image_id']\n",
        "#   bbox = annotation['bbox']\n",
        "#   x1=int(bbox[0])\n",
        "#   y1=int(bbox[1])\n",
        "#   w=int(bbox[2])\n",
        "#   h=int(bbox[3])\n",
        "#   filename = getImageNameByImageId(data['images'],image_id)\n",
        "#   img = cv2.imread(img_path+filename)\n",
        "\n",
        "#   cropped_image = img[y1:y1+h, x1:x1+w]\n",
        "\n",
        "#   border_size = 20\n",
        "#   border = cv2.copyMakeBorder(\n",
        "#       cropped_image,\n",
        "#       top=border_size,\n",
        "#       bottom=border_size,\n",
        "#       left=border_size,\n",
        "#       right=border_size,\n",
        "#       borderType=cv2.BORDER_CONSTANT,\n",
        "#       value=[128,128,128]\n",
        "#   )\n",
        "\n",
        "#   img300 = resizeImage(300,300,border)\n",
        "#   imgEdge = cv2.edgePreservingFilter(img300, flags=1, sigma_s=100, sigma_r=0.3)\n",
        "#   imgGray = cv2.cvtColor(imgEdge, cv2.COLOR_BGR2GRAY)\n",
        "#   imgLap = cv2.Laplacian(imgGray, cv2.CV_64F, ksize=5)\n",
        "#   cv2.imwrite(os.path.join(path , 'window'+str(i)+'.jpg'), imgLap)\n",
        "#   i+=1\n",
        "#   print(i)\n",
        "\n",
        "\n",
        "import json\n",
        "f = open('/content/drive/MyDrive/diplom/_annotations.coco.json')\n",
        "data = json.load(f)\n",
        "path = '/content/drive/MyDrive/diplom/colorImages/window/'\n",
        "img_path = \"/content/Window-detection-1/train/\"\n",
        "i=0\n",
        "for i in range(1000):\n",
        "  annotation = data['annotations'][i]\n",
        "  image_id = annotation['image_id']\n",
        "  filename = getImageNameByImageId(data['images'],image_id)\n",
        "  img = cv2.imread(img_path+filename)\n",
        "  cv2.imwrite(os.path.join(path , 'window'+str(i)+'.jpg'), img)\n",
        "  i+=1\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "lD0z0QDRUQzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resizeImage(width, height, image):\n",
        "  down_points = (width, height)\n",
        "  return cv2.resize(image, down_points, interpolation= cv2.INTER_LINEAR)"
      ],
      "metadata": {
        "id": "5SxvK-2WLNLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = 'https://drive.google.com/drive/folders/1EX_p0ncVGXKN3piWRa7h463ii8IAfFMy'\n",
        "path = '/content/drive/MyDrive/diplom/test/'\n",
        "img = cv2.imread(img_path)\n",
        "img300 = resizeImage(300,300,img)\n",
        "cv2_imshow(img300)\n",
        "image = cv2.flip(img300,1)\n",
        "cv2_imshow(image)\n",
        "# imgEdge = cv2.edgePreservingFilter(img300, flags=1, sigma_s=10, sigma_r=0.9)\n",
        "imgEdge= img300\n",
        "imgGray = cv2.cvtColor(imgEdge, cv2.COLOR_BGR2GRAY)\n",
        "cv2_imshow(imgEdge)\n",
        "imgLap = cv2.Laplacian(imgGray, cv2.CV_64F, ksize=5)\n",
        "cv2_imshow(imgLap)\n",
        "# img64 = resizeImage(64,64,imgLap)\n",
        "# cv2_imshow(img64)\n",
        "# cv2_imshow(cv2.flip(img64,1))\n",
        "\n",
        "\n",
        "# img64 = resizeImage(64,64,imgLap)\n",
        "# cv2_imshow(img64)\n",
        "\n",
        "\n",
        "resized = imutils.resize(imgLap, width=64,height=64)\n",
        "cv2_imshow(resized)\n",
        "cv2.imwrite(os.path.join(path , 'doorFinal.png'), resized)"
      ],
      "metadata": {
        "id": "_LjekJzudcyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_img_paths = glob.glob(\"/content/drive/MyDrive/diplom/photos/angles/*\")\n",
        "path = '/content/drive/MyDrive/diplom/readyImg/angle/'\n",
        "i=0\n",
        "print(len(all_img_paths))\n",
        "for img_path in all_img_paths:\n",
        "  img = cv2.imread(img_path)\n",
        "  img300 = resizeImage(300,300,img)\n",
        "  imgEdge = cv2.edgePreservingFilter(img300, flags=1, sigma_s=10, sigma_r=0.9)\n",
        "  imgGray = cv2.cvtColor(imgEdge, cv2.COLOR_BGR2GRAY)\n",
        "  imgLap = cv2.Laplacian(imgGray, cv2.CV_64F, ksize=5)\n",
        "  # img64 = imutils.resize(imgLap, width=64,height=64)\n",
        "  # cv2_imshow(img64)\n",
        "  cv2.imwrite(os.path.join(path , 'angle'+str(i)+'.jpg'), imgLap)\n",
        "  i+=1\n",
        "  flip = cv2.flip(imgLap,1)\n",
        "  cv2.imwrite(os.path.join(path , 'angle'+str(i)+'.jpg'), flip)\n",
        "  i+=1\n",
        "\n",
        "# img_path = '/content/drive/MyDrive/diplom/photos/doors/IMG_1840_126.jpg'\n",
        "\n",
        "# img = cv2.imread(img_path)\n",
        "# img300 = resizeImage(300,300,img)\n",
        "# cv2_imshow(img300)\n",
        "# image = cv2.flip(img300,1)\n",
        "# cv2_imshow(image)\n",
        "# imgEdge = cv2.edgePreservingFilter(img300, flags=1, sigma_s=10, sigma_r=0.9)\n",
        "# imgGray = cv2.cvtColor(imgEdge, cv2.COLOR_BGR2GRAY)\n",
        "# cv2_imshow(imgEdge)\n",
        "# imgLap = cv2.Laplacian(imgGray, cv2.CV_64F, ksize=5)\n",
        "# cv2_imshow(imgLap)\n",
        "# img64 = resizeImage(64,64,imgLap)\n",
        "# cv2_imshow(img64)\n",
        "# cv2_imshow(cv2.flip(img64,1))\n",
        "\n",
        "\n",
        "# # img64 = resizeImage(64,64,imgLap)\n",
        "# # cv2_imshow(img64)\n",
        "\n",
        "\n",
        "# resized = imutils.resize(imgLap, width=64,height=64)\n",
        "# cv2_imshow(resized)"
      ],
      "metadata": {
        "id": "iaqz1zLGDiyC",
        "outputId": "bb552091-f33f-4fa7-c47e-fb9ade3a0d38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DATADIR = \"/content/drive/MyDrive/diplom/colorImages/\"\n",
        "\n",
        "# LABELS = [\"door\", \"window\"]\n",
        "\n",
        "# X_TRAIN = []\n",
        "# Y_TRAIN = []\n",
        "\n",
        "# IMG_SIZE = 64\n",
        "# for category in LABELS:\n",
        "#     path = os.path.join(DATADIR, category)\n",
        "#     class_num = LABELS.index(category)\n",
        "#     for img in os.listdir(path):\n",
        "#         try:\n",
        "#             img_array = cv2.imread(os.path.join(path, img),cv2.IMREAD_GRAYSCALE)\n",
        "#             new_array = imutils.resize(img_array, IMG_SIZE,IMG_SIZE)\n",
        "#             # new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "#             X_TRAIN.append(new_array)\n",
        "#             Y_TRAIN.append(class_num)\n",
        "#         except Exception as e:\n",
        "#             pass\n",
        "# cv2_imshow(X_TRAIN[10])\n",
        "# X_TRAIN = np.array(X_TRAIN).reshape(-1, IMG_SIZE, IMG_SIZE,1)\n",
        "# Y_TRAIN = np.array(Y_TRAIN)\n",
        "# cv2_imshow(X_TRAIN[10])\n",
        "# X_TRAIN = X_TRAIN/255\n",
        "\n",
        "IMG_SIZE = 64\n",
        "DATADIR = \"/content/drive/MyDrive/diplom/colorImages/\"\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  DATADIR,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(IMG_SIZE, IMG_SIZE),\n",
        "  batch_size=5)"
      ],
      "metadata": {
        "id": "sn9QJ-FrjZUe",
        "outputId": "ddb4bfe5-b900-46dc-9304-68de6278fe16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3868 files belonging to 3 classes.\n",
            "Using 3095 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  DATADIR,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(IMG_SIZE, IMG_SIZE),\n",
        "  batch_size=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4Vm2BP5C9lH",
        "outputId": "00c81dac-a1b2-49b3-b9ab-f564d05cdab9"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3868 files belonging to 3 classes.\n",
            "Using 773 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)\n",
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\",\n",
        "                      input_shape=(IMG_SIZE,\n",
        "                                  IMG_SIZE,\n",
        "                                  3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "  ]\n",
        ")\n",
        "\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# model = models.Sequential()\n",
        "# model.add(data_augmentation),\n",
        "# model.add(layers.Rescaling(1./255, input_shape=(IMG_SIZE, IMG_SIZE, 3))),\n",
        "# model.add(layers.Conv2D(16, 3, padding='same', activation='relu')),\n",
        "# model.add(layers.MaxPooling2D()),\n",
        "# model.add(layers.Conv2D(32, 3, padding='same', activation='relu')),\n",
        "# model.add(layers.MaxPooling2D()),\n",
        "# model.add(layers.Conv2D(64, 3, padding='same', activation='relu')),\n",
        "# model.add(layers.MaxPooling2D()),\n",
        "# model.add(layers.Dropout(0.2)),\n",
        "# model.add(layers.Flatten()),\n",
        "# model.add(layers.Dense(128, activation='relu')),\n",
        "# model.add(layers.Dense(num_classes))\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(data_augmentation),\n",
        "model.add(layers.Rescaling(1./255, input_shape=(IMG_SIZE, IMG_SIZE, 3))),\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(num_classes))\n",
        "model.add(layers.Activation(\"softmax\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhnExcEIDQge",
        "outputId": "ecb7d24e-a998-4e98-e27b-2512fe4904e9"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['door', 'stair', 'window']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nJx8QdFZEE3E"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=2\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1TH5DSiErFB",
        "outputId": "d472e0d5-c6b3-4bb0-abde-6205c315aaff"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "619/619 [==============================] - 42s 67ms/step - loss: 0.1122 - accuracy: 0.9628 - val_loss: 0.3018 - val_accuracy: 0.9107\n",
            "Epoch 2/2\n",
            "619/619 [==============================] - 44s 71ms/step - loss: 0.1205 - accuracy: 0.9551 - val_loss: 0.2209 - val_accuracy: 0.9418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/diplom/model10.keras')"
      ],
      "metadata": {
        "id": "xySG4YNd1Beh"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.models.load_model('/content/drive/MyDrive/diplom/model9.keras')\n",
        "TESTDIR = \"/content/drive/MyDrive/diplom/test/s1.jpg\"\n",
        "validDir = glob.glob(\"/content/drive/MyDrive/diplom/test/validStairs/*\")\n",
        "for img_path in validDir:\n",
        "  img = tf.keras.utils.load_img(\n",
        "      img_path, target_size=(IMG_SIZE, IMG_SIZE)\n",
        "  )\n",
        "  img_array = tf.keras.utils.img_to_array(img)\n",
        "  img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "  predictions = model.predict(img_array)\n",
        "  score = tf.nn.softmax(predictions[0])\n",
        "  print(\n",
        "      \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "      .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leGHIQSXFytR",
        "outputId": "ffc7078c-71e6-414f-d455-d5bf36623f4c"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "This image most likely belongs to stair with a 55.55 percent confidence.\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "This image most likely belongs to stair with a 56.86 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "This image most likely belongs to stair with a 57.57 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.55 percent confidence.\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "This image most likely belongs to stair with a 57.60 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "This image most likely belongs to stair with a 50.03 percent confidence.\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "This image most likely belongs to stair with a 57.59 percent confidence.\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "This image most likely belongs to stair with a 51.75 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.60 percent confidence.\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "This image most likely belongs to stair with a 56.96 percent confidence.\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "This image most likely belongs to stair with a 57.18 percent confidence.\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "This image most likely belongs to stair with a 57.27 percent confidence.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "This image most likely belongs to stair with a 57.25 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 55.27 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.56 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 55.85 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.57 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to window with a 53.99 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 49.89 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 56.95 percent confidence.\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "This image most likely belongs to stair with a 57.57 percent confidence.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 54.96 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.60 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 56.93 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "This image most likely belongs to stair with a 57.57 percent confidence.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "This image most likely belongs to stair with a 57.37 percent confidence.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "This image most likely belongs to stair with a 51.20 percent confidence.\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "This image most likely belongs to stair with a 57.41 percent confidence.\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "This image most likely belongs to stair with a 57.15 percent confidence.\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "This image most likely belongs to stair with a 56.30 percent confidence.\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "This image most likely belongs to stair with a 57.20 percent confidence.\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "This image most likely belongs to window with a 45.35 percent confidence.\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "This image most likely belongs to stair with a 55.63 percent confidence.\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "This image most likely belongs to stair with a 57.60 percent confidence.\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "This image most likely belongs to window with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "This image most likely belongs to stair with a 57.55 percent confidence.\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "This image most likely belongs to stair with a 57.27 percent confidence.\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "This image most likely belongs to stair with a 57.37 percent confidence.\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "This image most likely belongs to door with a 50.23 percent confidence.\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "This image most likely belongs to stair with a 56.84 percent confidence.\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.29 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to window with a 57.16 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.32 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.53 percent confidence.\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "This image most likely belongs to stair with a 56.37 percent confidence.\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 49.78 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.23 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "This image most likely belongs to stair with a 53.38 percent confidence.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.60 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.16 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.60 percent confidence.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "This image most likely belongs to stair with a 57.57 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "This image most likely belongs to stair with a 57.49 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.58 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.58 percent confidence.\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.59 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "This image most likely belongs to stair with a 51.75 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "This image most likely belongs to stair with a 55.68 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.16 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.53 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "This image most likely belongs to stair with a 42.15 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "This image most likely belongs to stair with a 57.58 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.50 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.58 percent confidence.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "This image most likely belongs to stair with a 57.52 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 48.07 percent confidence.\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.42 percent confidence.\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.55 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.07 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 56.68 percent confidence.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "This image most likely belongs to stair with a 57.59 percent confidence.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "This image most likely belongs to stair with a 53.86 percent confidence.\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "This image most likely belongs to stair with a 43.61 percent confidence.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "This image most likely belongs to window with a 56.91 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.57 percent confidence.\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "This image most likely belongs to stair with a 57.30 percent confidence.\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "This image most likely belongs to stair with a 57.42 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "This image most likely belongs to stair with a 57.38 percent confidence.\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "This image most likely belongs to stair with a 55.55 percent confidence.\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "This image most likely belongs to window with a 50.12 percent confidence.\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "This image most likely belongs to stair with a 57.60 percent confidence.\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "This image most likely belongs to stair with a 56.29 percent confidence.\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "This image most likely belongs to stair with a 51.03 percent confidence.\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "This image most likely belongs to stair with a 56.23 percent confidence.\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "This image most likely belongs to stair with a 51.13 percent confidence.\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "This image most likely belongs to stair with a 57.57 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "This image most likely belongs to stair with a 55.45 percent confidence.\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "This image most likely belongs to stair with a 56.83 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.48 percent confidence.\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.58 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.60 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "This image most likely belongs to stair with a 57.11 percent confidence.\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 49.35 percent confidence.\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "This image most likely belongs to stair with a 57.56 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 56.38 percent confidence.\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "This image most likely belongs to stair with a 57.38 percent confidence.\n",
            "1/1 [==============================] - 0s 141ms/step\n",
            "This image most likely belongs to stair with a 57.61 percent confidence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_TRAIN))\n",
        "print(len(Y_TRAIN))\n",
        "#print(X_TRAIN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLtqDTOuwZkT",
        "outputId": "d13b0f3d-ea38-426f-d91c-728c8492b23d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11979\n",
            "11979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(2))\n",
        "model.add(layers.Activation(\"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8-lbAcBhqNUT",
        "outputId": "2fbdd473-5a15-4af5-b84a-4baf6c08d666",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_27 (Conv2D)          (None, 62, 62, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPooli  (None, 31, 31, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 29, 29, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPooli  (None, 14, 14, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 12, 12, 64)        36928     \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 64)                589888    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 2)                 130       \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 645762 (2.46 MB)\n",
            "Trainable params: 645762 (2.46 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "# model.add(layers.Conv2D(32, (5, 5), activation='relu',padding='same' ,input_shape=(64, 64,3)))\n",
        "model.add(layers.Conv2D(32, (5, 5), activation='relu',padding='same' ,input_shape=(64, 64,1)))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(layers.Activation(\"relu\"))\n",
        "\n",
        "model.add(layers.Conv2D(32, (5, 5), activation='relu',padding='same' ,input_shape=(32, 32,1)))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(layers.Activation(\"relu\"))\n",
        "\n",
        "model.add(layers.Conv2D(64, (5, 5), activation='relu',padding='same' ,input_shape=(16, 16,1)))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(layers.Activation(\"relu\"))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64))\n",
        "model.add(layers.Dense(2))\n",
        "model.add(layers.Activation(\"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUMkoJGmUZOf",
        "outputId": "0d57904a-4857-4c6a-df98-f114fd213dd2"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 32)        832       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 32)        25632     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 4, 4, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                65600     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 143458 (560.38 KB)\n",
            "Trainable params: 143458 (560.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_TRAIN, Y_TRAIN, batch_size=32, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2OsT_xJ4HRl",
        "outputId": "2d7e2528-05b2-4a7f-f5f7-1a8629c127fd"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 116s 308ms/step - loss: 0.0959 - accuracy: 0.9666\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 113s 302ms/step - loss: 0.0201 - accuracy: 0.9947\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 114s 305ms/step - loss: 0.0061 - accuracy: 0.9984\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 115s 308ms/step - loss: 0.0044 - accuracy: 0.9988\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 114s 303ms/step - loss: 0.0052 - accuracy: 0.9987\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7884409ad360>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "TESTDIR = \"/content/drive/MyDrive/diplom/test/window11111.jpg\"\n",
        "# for img in os.listdir(TESTDIR):\n",
        "#     try:\n",
        "#         img_array = cv2.imread(os.path.join(TESTDIR, img))\n",
        "#         new_img = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "#         new_shape = new_img.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "#         predictions = model.predict(new_shape)\n",
        "#         # plt.imshow(new_img)\n",
        "#         # print(predictions)\n",
        "#         print(LABELS[np.argmax(predictions)])\n",
        "#     except Exception as e:\n",
        "#         pass\n",
        "img_array = cv2.imread(TESTDIR)\n",
        "new_img = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "new_shape = new_img.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "predictions = model.predict(new_shape)\n",
        "plt.imshow(new_img)\n",
        "print(predictions)\n",
        "print(np.argmax(predictions))\n",
        "print(LABELS[np.argmax(predictions)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "y7DK3k3m2nCS",
        "outputId": "bc75584a-8ee9-406e-81aa-1a83fa614110"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n",
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]]\n",
            "0\n",
            "door\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}